{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import math\n",
    "from cmath import exp, pi\n",
    "from shutil import rmtree, copytree, move, copy\n",
    "from os import listdir, mkdir, remove\n",
    "from os.path import isfile, join, isdir\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create New Augmentation Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataAugTypes = ['Sharpness1', 'Sharpness2', 'GaussianBlur', 'EdgeDet1', 'EdgeDet2', 'EdgeDet3', 'EdgeDet4', 'EdgeDet5', 'EdgeDet6', \n",
    "'MotionBlur1', 'MotionBlur2', 'Box', 'Emboss1', 'Emboss2', 'FilterWithoutConv1', 'FilterWithoutConv2', 'FilterWithoutConv3', \n",
    "'FilterWithoutConv4', 'Deconvolution', 'Fourier1', 'Fourier2', 'HistEqualization1', 'HistEqualization2', 'GaussDiff1', \n",
    "'GaussDiff2', 'GaussDiff3', 'GaussDiff4', 'GaussDiff5', 'Harris', 'ShiTomasi', 'SIFT', 'ColorMap1', 'ColorMap2', 'ColorMap3',\n",
    "'ColorMap4', 'ColorMap5', 'ColorMap6', 'ColorMap7', 'ColorMap8', 'ColorMap9', 'ColorMap10', 'ColorMap11', 'ColorMap12', 'ColorMap13', \n",
    "'ColorMap14', 'ColorMap15', 'ColorMap16', 'ColorMap17', 'ColorMap18', 'ColorMap19', 'ColorMap20', 'ColorMap21', 'ColorMap22', \n",
    "'Dilation', 'Closing', 'Thresholding', 'AdaptiveThresholding']\n",
    "\n",
    "path = './train_images'\n",
    "original = path + '/Original/'\n",
    "\n",
    "for type in DataAugTypes:\n",
    "    newpath = path + '/' + type\n",
    "\n",
    "    if isdir(newpath):\n",
    "        rmtree(newpath, ignore_errors = False, onerror = None)\n",
    "\n",
    "    mkdir(newpath)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Appliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyKernel(kernel, path, original):\n",
    "    for i in range(0, 43):\n",
    "        path_dir = path + format(i, '05d') + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + format(i, '05d') + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            \n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_COLOR)\n",
    "\n",
    "            res = cv2.filter2D(src = img, ddepth = -1, kernel = kernel)\n",
    "            \n",
    "            cv2.imwrite(path_dir + f, res)\n",
    "\n",
    "\n",
    "\n",
    "def applyDoubleKernel(kernel1, kernel2, path, original):\n",
    "    for i in range(0, 43):\n",
    "        path_dir = path + format(i, '05d') + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + format(i, '05d') + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            \n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_COLOR)\n",
    "\n",
    "            resH = cv2.filter2D(src = img, ddepth = -1, kernel = kernel1)\n",
    "            resV = cv2.filter2D(src = img, ddepth = -1, kernel = kernel2)\n",
    "\n",
    "            res = resH + resV\n",
    "            cv2.imwrite(path_dir + f, res)\n",
    "\n",
    "\n",
    "\n",
    "def find_zero_crossings(res):\n",
    "    res = np.asarray(res)\n",
    "    res2 = [[np.abs(res[i][j] - res[i + 1][j])\n",
    "                if (res[i][j] <= 0 and res[i + 1][j] > 0) or (res[i][j] >= 0 and res[i + 1][j] < 0)  else 0\n",
    "                for j in range(1, res.shape[1] -1)] for i in range(1, res.shape[0] -1)]\n",
    "\n",
    "    res3 =  [[np.abs(res[i][j]-res[i][j+1])\n",
    "                if (res[i][j] <= 0 and res[i][j + 1] > 0) or (res[i][j] >= 0 and res[i][j + 1] < 0)  else 0\n",
    "                for j in range(1, res.shape[1] - 1)] for i in range(1, res.shape[0] - 1)]\n",
    "\n",
    "    res4 = np.asarray(res2) + np.asarray(res3)   \n",
    "  \n",
    "    return res4\n",
    "\n",
    "\n",
    "def applyLaplacianAlternative(kernel1, kernel2, path, original):\n",
    "    for i in range(0, 43):\n",
    "        path_dir = path + format(i, '05d') + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + format(i, '05d') + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            \n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_COLOR)\n",
    "\n",
    "            resX = signal.convolve2d(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), kernel1)\n",
    "            resY = signal.convolve2d(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), kernel2)\n",
    "\n",
    "            resT = resX + resY\n",
    "            \n",
    "            resZC = find_zero_crossings(resT)\n",
    "\n",
    "            cv2.imwrite(path_dir + f, resZC)\n",
    "\n",
    "\n",
    "\n",
    "def applyCanny(path, original):\n",
    "    for i in range(0, 43):\n",
    "        path_dir = path + format(i, '05d') + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + format(i, '05d') + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            \n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_COLOR)\n",
    "\n",
    "            res = cv2.Canny(img, 70, 90)\n",
    "\n",
    "            cv2.imwrite(path_dir + f, res)\n",
    "\n",
    "\n",
    "\n",
    "def applyFilterWithoutConv(path, original, filter):\n",
    "    for i in range(0, 43):\n",
    "        path_dir = path + format(i, '05d') + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + format(i, '05d') + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            \n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_COLOR)\n",
    "\n",
    "            if filter == 0:\n",
    "                res = cv2.medianBlur(img, 9)\n",
    "\n",
    "            elif filter == 1:\n",
    "                res = cv2.GaussianBlur(img, (7, 7), -1)\n",
    "\n",
    "            elif filter == 2:\n",
    "                res = cv2.bilateralFilter(img, 9, 75, 75)\n",
    "            \n",
    "            elif filter == 3:\n",
    "                gaussian = cv2.GaussianBlur(img, (45, 45), 0)\n",
    "                unsharp_mask = cv2.addWeighted(img, 1.0, gaussian, -1.0, 0)\n",
    "                res = cv2.medianBlur(unsharp_mask, 9)\n",
    "            else:\n",
    "                res = img\n",
    "\n",
    "            cv2.imwrite(path_dir + f, res)\n",
    "\n",
    "\n",
    "\n",
    "ANGLE = np.deg2rad(135)\n",
    "D = 22\n",
    "noise = 10 ** (-0.1 * 25)\n",
    "\n",
    "\n",
    "def blur_edge(img, d = 31):\n",
    "    h, w  = img.shape[:2]\n",
    "    \n",
    "    img_pad = cv2.copyMakeBorder(img, d, d, d, d, cv2.BORDER_WRAP)\n",
    "    img_blur = cv2.GaussianBlur(img_pad, (2 * d + 1, 2 * d + 1), -1)[d:-d, d:-d]\n",
    "    \n",
    "    y, x = np.indices((h, w))\n",
    "    dist = np.dstack([x, w - x - 1, y, h - y - 1]).min(-1)\n",
    "    w = np.minimum(np.float32(dist) / d, 1.0)\n",
    "    \n",
    "    return img * w + img_blur * (1 - w)\n",
    "\n",
    "\n",
    "def motion_kernel(angle, d, sz = 1):\n",
    "    kern = np.ones((1, d), np.float32)\n",
    "    c, s = np.cos(angle), np.sin(angle)\n",
    "    \n",
    "    A = np.float32([[c, -s, 0], [s, c, 0]])\n",
    "    sz2 = sz // 2\n",
    "    \n",
    "    A[:, 2] = (sz2, sz2) - np.dot(A[:,:2], ((d - 1) * 0.5, 0))\n",
    "    kern = cv2.warpAffine(kern, A, (sz, sz), flags = cv2.INTER_CUBIC)\n",
    "    \n",
    "    return kern\n",
    "\n",
    "\n",
    "def applyDeconvolution(path, original):\n",
    "    \n",
    "    for i in range(0, 43):\n",
    "        path_dir = path + format(i, '05d') + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + format(i, '05d') + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_GRAYSCALE)\n",
    "            img = np.float32(img) / 255.0\n",
    "\n",
    "            img_be = blur_edge(img)\n",
    "\n",
    "            img_aux = img_be\n",
    "            dft = cv2.dft(img_aux, flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "            dft_shift = np.fft.fftshift(dft)\n",
    "            \n",
    "            psf = motion_kernel(ANGLE, D)\n",
    "            \n",
    "            psf /= psf.sum()\n",
    "            psf_pad = np.zeros_like(img)\n",
    "            kh, kw = psf.shape\n",
    "            psf_pad[:kh, :kw] = psf\n",
    "            PSF = cv2.dft(psf_pad, flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "\n",
    "            PSF2 = (PSF ** 2).sum(-1)\n",
    "            iPSF = PSF.conjugate() / (PSF2 + noise)[..., np.newaxis]\n",
    "            RES = cv2.mulSpectrums(dft, iPSF, 0)\n",
    "            res = cv2.idft(RES, flags = cv2.DFT_SCALE | cv2.DFT_REAL_OUTPUT)\n",
    "            \n",
    "            res = np.float32(res) * 255\n",
    "            cv2.imwrite(path_dir + f, res)\n",
    "\n",
    "\n",
    "\n",
    "def gauss(std, x, y):\n",
    "    d = x ** 2 + y ** 2\n",
    "    g =  exp(-d / (2 * std ** 2))\n",
    "\n",
    "    return g\n",
    "\n",
    "    \n",
    "def gaussianLP(std, img_shape):\n",
    "    return np.asarray([[gauss(std, x-img_shape[0]/2,y-img_shape[1]/2)  for y in range(img_shape[1])] for x in range(img_shape[0])])\n",
    "\n",
    "\n",
    "def gaussianHP(std, img_shape):\n",
    "    return np.asarray([[1 - gauss(std, x - img_shape[0] / 2, y - img_shape[1] / 2)  for y in range(img_shape[1])] for x in range(img_shape[0])])        \n",
    "\n",
    "\n",
    "filter_strength = 8\n",
    "\n",
    "def applyFourier(path, original, filter):\n",
    "    for i in range(0, 43):\n",
    "        path_dir = path + format(i, '05d') + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + format(i, '05d') + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            image_grey_fourier = np.fft.fft2(img)\n",
    "\n",
    "            if filter == 0:\n",
    "                GaussianLP = gaussianLP(filter_strength, img.shape)\n",
    "                filtered = np.fft.fftshift(image_grey_fourier) * GaussianLP\n",
    "                LowPass = np.fft.ifftshift(filtered)\n",
    "                res = np.fft.ifft2(LowPass)\n",
    "\n",
    "            elif filter == 1:\n",
    "                GaussianHP = gaussianHP(filter_strength, img.shape)\n",
    "                filtered = np.fft.fftshift(image_grey_fourier) * GaussianHP\n",
    "                HighPass = np.fft.ifftshift(filtered)\n",
    "                res = np.fft.ifft2(HighPass)\n",
    "\n",
    "            else: \n",
    "                res = img\n",
    "\n",
    "            cv2.imwrite(path_dir + f, res.real)\n",
    "\n",
    "\n",
    "\n",
    "def applyHistogramEqualization(path, original, filter):\n",
    "    for i in range(0, 43):\n",
    "        path_dir = path + format(i, '05d') + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + format(i, '05d') + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if filter == 0:\n",
    "                res = cv2.equalizeHist(img)\n",
    "\n",
    "            elif filter == 1:\n",
    "                clahe = cv2.createCLAHE(clipLimit = 2.0, tileGridSize = (8, 8))\n",
    "                res = clahe.apply(img)\n",
    "\n",
    "            else:\n",
    "                res = img\n",
    "\n",
    "            cv2.imwrite(path_dir + f, res)\n",
    "\n",
    "\n",
    "\n",
    "def gaussian_kernel(dimension):\n",
    "    x = cv2.getGaussianKernel(dimension, -1)\n",
    "    kernel = x.dot(x.T)\n",
    "\n",
    "    return kernel\n",
    "\n",
    "\n",
    "def applyGaussDiff(path, original, size):\n",
    "    for i in range(0, 43):\n",
    "        path_dir = path + format(i, '05d') + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + format(i, '05d') + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            kernel1 = gaussian_kernel(size - 2)\n",
    "            kernel2 = gaussian_kernel(size)\n",
    "\n",
    "            res1 = cv2.filter2D(img, -1, kernel1)\n",
    "            res2 = cv2.filter2D(img, -1, kernel2)\n",
    "\n",
    "            res = res2 - res1\n",
    "\n",
    "            cv2.imwrite(path_dir + f, res)\n",
    "\n",
    "\n",
    "\n",
    "def applyHarrisCorners(path, original):\n",
    "    for i in range(0, 43):\n",
    "        path_dir = path + format(i, '05d') + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + format(i, '05d') + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_GRAYSCALE)\n",
    "            dst = cv2.cornerHarris(img, 2, 11, 0.04)\n",
    "            dst = cv2.dilate(dst, None)\n",
    "\n",
    "            res = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "            res[np.abs(dst) > 0.04 * dst.max()] = [0, 255, 0]\n",
    "\n",
    "            cv2.imwrite(path_dir + f, res)\n",
    "\n",
    "\n",
    "\n",
    "def applyShiTomasi(path, original):\n",
    "    for i in range(0, 43):\n",
    "        path_dir = path + format(i, '05d') + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + format(i, '05d') + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            corners = cv2.goodFeaturesToTrack(img, 2500, 0.01, 10)\n",
    "\n",
    "            corners = np.int0(corners)\n",
    "\n",
    "            res = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "            for i in corners:\n",
    "                x, y = i.ravel()\n",
    "                cv2.circle(res, (x, y), 1, 255, -1)\n",
    "\n",
    "            cv2.imwrite(path_dir + f, res)\n",
    "\n",
    "\n",
    "\n",
    "def applySIFT(path, original):\n",
    "    for i in range(0, 43):\n",
    "        path_dir = path + format(i, '05d') + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + format(i, '05d') + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            sift = cv2.SIFT_create()\n",
    "            kp = sift.detect(img, None)\n",
    "\n",
    "            res = cv2.drawKeypoints(img, kp, img, flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "            cv2.imwrite(path_dir + f, res)\n",
    "\n",
    "\n",
    "\n",
    "def applyColorMap(path, original, map):\n",
    "    for i in range(0, 43):\n",
    "        path_dir = path + format(i, '05d') + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + format(i, '05d') + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_COLOR)\n",
    "\n",
    "            res = cv2.applyColorMap(img, map)\n",
    "\n",
    "            cv2.imwrite(path_dir + f, res)\n",
    "\n",
    "\n",
    "\n",
    "def applyTransform(path, original, flag):\n",
    "    for i in range(0, 43):\n",
    "        path_dir = path + format(i, '05d') + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + format(i, '05d') + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_COLOR)\n",
    "\n",
    "            if flag == 0:\n",
    "                kernel = np.ones((3, 3), np.uint8)\n",
    "                res = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "            elif flag == 1:\n",
    "                kernel = np.ones((3, 3), np.uint8)\n",
    "                res = cv2.dilate(img, kernel, iterations = 1)\n",
    "\n",
    "            else:\n",
    "                res = img\n",
    "\n",
    "            cv2.imwrite(path_dir + f, res)\n",
    "\n",
    "\n",
    "\n",
    "def applyThresholding(path, original, flag):\n",
    "    for i in range(0, 43):\n",
    "        path_dir = path + format(i, '05d') + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + format(i, '05d') + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            img = cv2.imread(original_dir + f, 0)\n",
    "\n",
    "            if flag == 0:\n",
    "                img = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "                _, res = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "            elif flag == 1: \n",
    "                img = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "                res = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 3, 5)\n",
    "\n",
    "            else:\n",
    "                res = img\n",
    "\n",
    "            cv2.imwrite(path_dir + f, res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sharpness Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel1 = np.array([[0, -1, 0],\n",
    "                    [-1, 5,-1],\n",
    "                    [0, -1, 0]])\n",
    "\n",
    "kernel2 = np.array([[-1, -1, -1],\n",
    "                    [-1,  9, -1],\n",
    "                    [-1, -1, -1]])\n",
    "\n",
    "\n",
    "kernel1 = kernel1 / np.sum(kernel1)\n",
    "\n",
    "kernel2 = kernel2 / np.sum(kernel2)\n",
    "\n",
    "path1 = './train_images/Sharpness1/'\n",
    "path2 = './train_images/Sharpness2/'\n",
    "\n",
    "applyKernel(kernel1, path1, original)\n",
    "applyKernel(kernel2, path2, original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(dimension):\n",
    "    x = cv2.getGaussianKernel(dimension, -1)\n",
    "    kernel = x.dot(x.T)\n",
    "    return kernel\n",
    "\n",
    "kernel = gaussian_kernel(3)\n",
    "\n",
    "path = './train_images/GaussianBlur/'\n",
    "\n",
    "applyKernel(kernel, path, original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Laplacian Approximations\n",
    "kernel1 = np.array([[-1, -1, -1],\n",
    "                    [-1, 8, -1],\n",
    "                    [-1, -1, -1]])\n",
    "\n",
    "kernel2 = np.array([[0, 1, 0],\n",
    "                    [1, -4, 1],\n",
    "                    [0, 1, 0]])\n",
    "\n",
    "\n",
    "# Prewit\n",
    "kernel3H = np.array([[-1, -1, -1],\n",
    "                     [0,  0,  0],\n",
    "                     [1,  1,  1]])\n",
    "\n",
    "kernel3V = np.array([[-1, 0, 1],\n",
    "                     [-1, 0, 1],\n",
    "                     [-1, 0, 1]])\n",
    "\n",
    "\n",
    "# Scharr\n",
    "kernel4H = np.array([[-3, -10, -3],\n",
    "                     [0,   0,  0],\n",
    "                     [3,  10,  3]])\n",
    "\n",
    "kernel4V = np.array([[-3, 0,  3],\n",
    "                     [-10, 0, 10],\n",
    "                     [-3, 0,  3]])\n",
    "\n",
    "\n",
    "# Laplacian Alternative\n",
    "kernel5X = np.array([[-1, 2, -1],\n",
    "                     [-2, 4, -2],\n",
    "                     [-1, 2, -1]])\n",
    "\n",
    "kernel5Y = np.array([[-1, -2, -1],\n",
    "                     [2,  4,  2],\n",
    "                     [-1, -2, -1]])\n",
    "\n",
    "\n",
    "path1 = './train_images/EdgeDet1/'\n",
    "path2 = './train_images/EdgeDet2/'\n",
    "path3 = './train_images/EdgeDet3/'\n",
    "path4 = './train_images/EdgeDet4/'\n",
    "path5 = './train_images/EdgeDet5/'\n",
    "path6 = './train_images/EdgeDet6/'\n",
    "\n",
    "applyKernel(kernel1, path1, original)\n",
    "applyKernel(kernel2, path2, original)\n",
    "applyDoubleKernel(kernel3H, kernel3V, path3, original)\n",
    "applyDoubleKernel(kernel4H, kernel4V, path4, original)\n",
    "applyLaplacianAlternative(kernel5X, kernel5Y, path5, original)\n",
    "applyCanny(path6, original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Motion Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel1 = np.array([[0, 0, 0, 0, 0, 0, 1],\n",
    "                    [0, 0, 0, 0, 0, 1, 0],\n",
    "                    [0, 0, 0, 0, 1, 0, 0],\n",
    "                    [0, 0, 0, 1, 0, 0, 0],\n",
    "                    [0, 0, 1, 0, 0, 0, 0],\n",
    "                    [0, 1, 0, 0, 0, 0, 0],\n",
    "                    [1, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "kernel2 = np.array([[0, 0, 0, 0, 0, 0, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0],\n",
    "                    [0, 0, 0, 0, 1, 1, 1],\n",
    "                    [0, 0, 1, 1, 0, 0, 0],\n",
    "                    [1, 1, 0, 0, 0, 0, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "kernel1 = kernel1 / np.sum(kernel1)\n",
    "kernel2 = kernel2 / np.sum(kernel2)\n",
    "\n",
    "path1 = './train_images/MotionBlur1/'\n",
    "path2 = './train_images/MotionBlur2/'\n",
    "\n",
    "applyKernel(kernel1, path1, original)\n",
    "applyKernel(kernel2, path2, original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Box filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 7\n",
    "kernel = np.ones((dim, dim))\n",
    "kernel = kernel / np.sum(kernel)\n",
    "\n",
    "path = './train_images/Box/'\n",
    "\n",
    "applyKernel(kernel, path, original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Emboss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel1 = np.array([[-2, -1, 0],\n",
    "                    [-1,  1, 1],\n",
    "                    [ 0,  1, 2]])\n",
    "\n",
    "kernel2 = np.array([[0,  1, 2],\n",
    "                    [-1,  1, 1],\n",
    "                    [-2, -1, 0]])\n",
    "\n",
    "kernel1 = kernel1 / np.sum(kernel1)\n",
    "\n",
    "kernel2 = kernel2 / np.sum(kernel2)\n",
    "\n",
    "path1 = './train_images/Emboss1/'\n",
    "path2 = './train_images/Emboss2/'\n",
    "\n",
    "applyKernel(kernel1, path1, original)\n",
    "applyKernel(kernel2, path2, original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Filters Without Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = './train_images/FilterWithoutConv1/'\n",
    "path2 = './train_images/FilterWithoutConv2/'\n",
    "path3 = './train_images/FilterWithoutConv3/'\n",
    "path4 = './train_images/FilterWithoutConv4/'\n",
    "\n",
    "\n",
    "# Median Blur\n",
    "applyFilterWithoutConv(path1, original, filter = 0)\n",
    "\n",
    "# Gaussian Blur\n",
    "applyFilterWithoutConv(path2, original, filter = 1)\n",
    "\n",
    "# Bilateral Filter\n",
    "applyFilterWithoutConv(path3, original, filter = 2)\n",
    "\n",
    "# Unsharp Mask\n",
    "applyFilterWithoutConv(path4, original, filter = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './train_images/Deconvolution/'\n",
    "\n",
    "applyDeconvolution(path, original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = './train_images/Fourier1/'\n",
    "path2 = './train_images/Fourier2/'\n",
    "\n",
    "applyFourier(path1, original, 0)\n",
    "applyFourier(path2, original, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Histogram Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = './train_images/HistEqualization1/'\n",
    "path2 = './train_images/HistEqualization2/'\n",
    "\n",
    "# Normal Equalization\n",
    "applyHistogramEqualization(path1, original, 0)\n",
    "\n",
    "# CLAHE\n",
    "applyHistogramEqualization(path2, original, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Difference of Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = './train_images/GaussDiff1/'\n",
    "path2 = './train_images/GaussDiff2/'\n",
    "path3 = './train_images/GaussDiff3/'\n",
    "path4 = './train_images/GaussDiff4/'\n",
    "path5 = './train_images/GaussDiff5/'\n",
    "\n",
    "applyGaussDiff(path1, original, 3)\n",
    "applyGaussDiff(path2, original, 5)\n",
    "applyGaussDiff(path3, original, 7)\n",
    "applyGaussDiff(path4, original, 9)\n",
    "applyGaussDiff(path5, original, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Feature Detection Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = './train_images/Harris/'\n",
    "path2 = './train_images/ShiTomasi/'\n",
    "path3 = './train_images/SIFT/'\n",
    "\n",
    "# Harris Corners\n",
    "applyHarrisCorners(path1, original)\n",
    "\n",
    "# Shi-Tomasi\n",
    "applyShiTomasi(path2, original)\n",
    "\n",
    "# SIFT\n",
    "applySIFT(path3, original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Color Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 22):\n",
    "    path = f'./train_images/ColorMap{i + 1}/'\n",
    "    applyColorMap(path, original, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Closing and Dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = './train_images/Closing/'\n",
    "path2 = './train_images/Dilation/'\n",
    "\n",
    "applyTransform(path1, original, 0)\n",
    "applyTransform(path2, original, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Thresholding, Adaptive Thresholding, And Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = './train_images/Thresholding/'\n",
    "path2 = './train_images/AdaptiveThresholding/'\n",
    "\n",
    "applyThresholding(path1, original, 0)\n",
    "applyThresholding(path2, original, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Set Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './train_images'\n",
    "\n",
    "subfolders = [f.path for f in os.scandir(path) if f.is_dir()]\n",
    "\n",
    "for sf in subfolders:\n",
    "    new_path = re.sub(r'train_images', r'val_images', sf)\n",
    "\n",
    "    if isdir(new_path):\n",
    "        rmtree(new_path, ignore_errors = False, onerror = None)\n",
    "\n",
    "    mkdir(new_path)\n",
    "\n",
    "    for i in range(0, 43):\n",
    "        path_dir = sf + '/' + format(i, '05d') + '/'\n",
    "        new_path_dir = new_path + '/' + format(i, '05d') + '/'\n",
    "\n",
    "        onlyfiles = [f for f in listdir(path_dir) if isfile(join(path_dir, f))]\n",
    "        \n",
    "        length = len(onlyfiles)\n",
    "        train_length = int(length * 0.8)\n",
    "        val_length = length - train_length\n",
    "\n",
    "        valfiles = np.random.choice(onlyfiles, size = val_length, replace = False)\n",
    "\n",
    "        if isdir(new_path_dir):\n",
    "            rmtree(new_path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(new_path_dir)\n",
    "\n",
    "        for v in valfiles:\n",
    "            move(path_dir + v, new_path_dir + v)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16a84799b4554b55119e03db3af09132791ba03da067a3440fe10ca44b449a97"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
